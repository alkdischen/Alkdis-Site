<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>[Paper] SiamMAE论文解读 - Alkdis Chen</title><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
	<link rel="manifest" href="/site.webmanifest">

	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta itemprop="name" content="[Paper] SiamMAE论文解读">
<meta itemprop="description" content="Abstract 一句话概括本文的贡献，作者将MAE方法由图像端扩展到视频端，并命名为SiamMAE。
预测的方法简单来说，保持过去的视频帧数保持不变，masked掉未来的95%的帧数，进行表征学习。
最终结果作者表示具有优异的表现，同时可以对图像边缘进行检测。
Introduction 视觉学习不能忽略时间，时间维度下，人类可以在遮挡，视觉点变化，对象移动变换，等阻碍下进行学习，这对无监督学习非常关键。
目前一个比较强大的自监督学习方法（范式）是预测学习，类似于MAE。
作者这里高度概括了对比学习与预测学习。
预测学习很强大，但是落后于对比自监督。 对比学习直观上适用于各种任务，因为可以对比方法可以有着多种数据增强。 但是，对比学习依赖于细节选择，以及附加内容，总之就是需要各种条件才能进行学习，否则会崩溃。 随后，作者讲了一下MAE的优劣：
MAE将MVM方法从NLP引入到CV，有着很好的效果，但是优缺点如下: 1. 本职工作是像素重建，finetune之后有着优秀的性能，但是zeroshot效果不佳。 2. 视频方向，已经有拓展可以用于视频方向，内容如下：掩盖所有帧的大部分补丁。这导致其工作效果不佳， 作者认为，时间维度是图像中一个特殊的维度，因为时间维度上，过去与未来不是对称的，而现有的MAE是对称的处理过去帧与未来帧相同比例的mask。实验验证，对称帧率的mask训练效果并不比图像训练好。
综上，作者提出SiamMAE，通过过去未来帧数的不对称训练，来实现视频更好的训练MAE，获得高于图像训练的效果。
SiamMAE的结构图：
如果看过CrossViT，就会发现这个结构与交叉ViT完全一致，只是将不同维度的batch换成了mask与unmasked进行cross。"><meta itemprop="datePublished" content="2023-08-22T10:56:46+08:00" />
<meta itemprop="dateModified" content="2023-08-22T10:56:46+08:00" />
<meta itemprop="wordCount" content="21">
<meta itemprop="keywords" content="" /><meta property="og:title" content="[Paper] SiamMAE论文解读" />
<meta property="og:description" content="Abstract 一句话概括本文的贡献，作者将MAE方法由图像端扩展到视频端，并命名为SiamMAE。
预测的方法简单来说，保持过去的视频帧数保持不变，masked掉未来的95%的帧数，进行表征学习。
最终结果作者表示具有优异的表现，同时可以对图像边缘进行检测。
Introduction 视觉学习不能忽略时间，时间维度下，人类可以在遮挡，视觉点变化，对象移动变换，等阻碍下进行学习，这对无监督学习非常关键。
目前一个比较强大的自监督学习方法（范式）是预测学习，类似于MAE。
作者这里高度概括了对比学习与预测学习。
预测学习很强大，但是落后于对比自监督。 对比学习直观上适用于各种任务，因为可以对比方法可以有着多种数据增强。 但是，对比学习依赖于细节选择，以及附加内容，总之就是需要各种条件才能进行学习，否则会崩溃。 随后，作者讲了一下MAE的优劣：
MAE将MVM方法从NLP引入到CV，有着很好的效果，但是优缺点如下: 1. 本职工作是像素重建，finetune之后有着优秀的性能，但是zeroshot效果不佳。 2. 视频方向，已经有拓展可以用于视频方向，内容如下：掩盖所有帧的大部分补丁。这导致其工作效果不佳， 作者认为，时间维度是图像中一个特殊的维度，因为时间维度上，过去与未来不是对称的，而现有的MAE是对称的处理过去帧与未来帧相同比例的mask。实验验证，对称帧率的mask训练效果并不比图像训练好。
综上，作者提出SiamMAE，通过过去未来帧数的不对称训练，来实现视频更好的训练MAE，获得高于图像训练的效果。
SiamMAE的结构图：
如果看过CrossViT，就会发现这个结构与交叉ViT完全一致，只是将不同维度的batch换成了mask与unmasked进行cross。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.alkdischen.cn/posts/articles/2023-08-22-paper-siammae/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2023-08-22T10:56:46+08:00" />
<meta property="article:modified_time" content="2023-08-22T10:56:46+08:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="[Paper] SiamMAE论文解读"/>
<meta name="twitter:description" content="Abstract 一句话概括本文的贡献，作者将MAE方法由图像端扩展到视频端，并命名为SiamMAE。
预测的方法简单来说，保持过去的视频帧数保持不变，masked掉未来的95%的帧数，进行表征学习。
最终结果作者表示具有优异的表现，同时可以对图像边缘进行检测。
Introduction 视觉学习不能忽略时间，时间维度下，人类可以在遮挡，视觉点变化，对象移动变换，等阻碍下进行学习，这对无监督学习非常关键。
目前一个比较强大的自监督学习方法（范式）是预测学习，类似于MAE。
作者这里高度概括了对比学习与预测学习。
预测学习很强大，但是落后于对比自监督。 对比学习直观上适用于各种任务，因为可以对比方法可以有着多种数据增强。 但是，对比学习依赖于细节选择，以及附加内容，总之就是需要各种条件才能进行学习，否则会崩溃。 随后，作者讲了一下MAE的优劣：
MAE将MVM方法从NLP引入到CV，有着很好的效果，但是优缺点如下: 1. 本职工作是像素重建，finetune之后有着优秀的性能，但是zeroshot效果不佳。 2. 视频方向，已经有拓展可以用于视频方向，内容如下：掩盖所有帧的大部分补丁。这导致其工作效果不佳， 作者认为，时间维度是图像中一个特殊的维度，因为时间维度上，过去与未来不是对称的，而现有的MAE是对称的处理过去帧与未来帧相同比例的mask。实验验证，对称帧率的mask训练效果并不比图像训练好。
综上，作者提出SiamMAE，通过过去未来帧数的不对称训练，来实现视频更好的训练MAE，获得高于图像训练的效果。
SiamMAE的结构图：
如果看过CrossViT，就会发现这个结构与交叉ViT完全一致，只是将不同维度的batch换成了mask与unmasked进行cross。"/>
<link href='https://fonts.googleapis.com/css?family=Playfair+Display:700' rel='stylesheet' type='text/css'>
	<link rel="stylesheet" type="text/css" media="screen" href="https://www.alkdischen.cn/css/normalize.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="https://www.alkdischen.cn/css/main.css" />

        <link id="dark-scheme" rel="stylesheet" type="text/css" href="https://www.alkdischen.cn/css/dark.css" />

	<script src="https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js"></script>
		<script src="https://www.alkdischen.cn/js/main.js"></script>
	
</head>



<body>
	<div class="container wrapper">
		<div class="header">
	
		<div class="avatar">
			<a href="https://www.alkdischen.cn/">
				<img src="https://picgo-1313480473.cos.ap-shanghai.myqcloud.com/Blog/sculpture.jpg" alt="Alkdis Chen" />
			</a>
		</div>
	
	<h1 class="site-title"><a href="https://www.alkdischen.cn/">Alkdis Chen</a></h1>
	<div class="site-description"><p>Coding with wind</p><nav class="nav social">
			<ul class="flat"><li><a href="https://github.com/ikoltech" title="GitHub"><i data-feather="github"></i></a></li></ul>
		</nav>
	</div>

	<nav class="nav">
		<ul class="flat">
			
			<li>
				<a href="/">Home</a>
			</li>
			
			<li>
				<a href="/posts">推文</a>
			</li>
			
			<li>
				<a href="/posts-ng">Posts</a>
			</li>
			
			<li>
				<a href="/pages/about">About</a>
			</li>
			
			<li>
				<a href="/tags">Tags</a>
			</li>
			
		</ul>
	</nav>
</div>


		<div class="post">
			<div class="post-header">
				
					
						<div class="meta">
							<div class="date">
								<span class="day">22</span>
								<span class="rest">Aug 2023</span>
							</div>
						</div>
					
				
				<div class="matter">
					<h1 class="title">[Paper] SiamMAE论文解读</h1>
					
				</div>
			</div>
					
			<div>
				
					<nav id="TableOfContents">
  <ul>
    <li><a href="#abstract">Abstract</a></li>
    <li><a href="#introduction">Introduction</a></li>
  </ul>
</nav>
					<hr>
				
			</div>
			<div class="markdown">
				<h2 id="abstract">Abstract</h2>
<p>一句话概括本文的贡献，作者将MAE方法由图像端扩展到视频端，并命名为SiamMAE。</p>
<p>预测的方法简单来说，保持过去的视频帧数保持不变，masked掉未来的95%的帧数，进行表征学习。</p>
<p>最终结果作者表示具有优异的表现，同时可以对图像边缘进行检测。</p>
<h2 id="introduction">Introduction</h2>
<p>视觉学习不能忽略时间，时间维度下，人类可以在遮挡，视觉点变化，对象移动变换，等阻碍下进行学习，这对无监督学习非常关键。</p>
<p>目前一个比较强大的自监督学习方法（范式）是预测学习，类似于MAE。</p>
<p>作者这里高度概括了对比学习与预测学习。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>预测学习很强大，但是落后于对比自监督。
</span></span><span style="display:flex;"><span>对比学习直观上适用于各种任务，因为可以对比方法可以有着多种数据增强。
</span></span><span style="display:flex;"><span>但是，对比学习依赖于细节选择，以及附加内容，总之就是需要各种条件才能进行学习，否则会崩溃。
</span></span></code></pre></div><p>随后，作者讲了一下MAE的优劣：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>MAE将MVM方法从NLP引入到CV，有着很好的效果，但是优缺点如下:
</span></span><span style="display:flex;"><span>1. 本职工作是像素重建，finetune之后有着优秀的性能，但是zeroshot效果不佳。
</span></span><span style="display:flex;"><span>2. 视频方向，已经有拓展可以用于视频方向，内容如下：掩盖所有帧的大部分补丁。这导致其工作效果不佳，
</span></span></code></pre></div><p>作者认为，时间维度是图像中一个特殊的维度，因为时间维度上，过去与未来不是对称的，而现有的MAE是对称的处理过去帧与未来帧相同比例的mask。实验验证，对称帧率的mask训练效果并不比图像训练好。</p>
<p>综上，作者提出SiamMAE，通过过去未来帧数的不对称训练，来实现视频更好的训练MAE，获得高于图像训练的效果。</p>
<p>SiamMAE的结构图：</p>
<p><img src="./structure.png" alt="structure"></p>
<p>如果看过CrossViT，就会发现这个结构与交叉ViT完全一致，只是将不同维度的batch换成了mask与unmasked进行cross。</p>

				
			</div>

			<div class="tags">
				
					
				
			</div></div>
	</div>
	

<div class="footer wrapper">
	<nav class="nav">
		<div>2023  © Alkdis Chen |  <a href="https://github.com/knadh/hugo-ink">Ink</a> theme on <a href="https://gohugo.io">Hugo</a>  
    
    <div class="wrap">
    

        
    </div>

    
    
    
    
    </div>
	</nav>
</div>







  

<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-52525161-8', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>
<script>feather.replace()</script>
</body>
</html>
